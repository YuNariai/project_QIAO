{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2538ca78-84da-4f90-b742-65f7929632b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "import pennylane.numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e0e65e7-2a52-499e-89e1-d1401e1c2168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.58778525+0.j,  0.80901699+0.j],\n",
       "       [ 0.80901699+0.j,  0.58778525+0.j]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#qml.matrix(qml.RY(0.2*np.pi,0)@qml.PauliX(0)@qml.RY(-0.2*np.pi,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f23d04b-b4a2-4086-b1bf-d6cec06ced27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=(np.load('./saved_data_PneumoniaMNIST/train_seqs_42.npz')['arr_0']) # train images\n",
    "\n",
    "train_label=np.load('./saved_data_PneumoniaMNIST/train_labels.npz')['arr_0']\n",
    "\n",
    "\n",
    "Y = np.array([int(y) for y in train_label]) # train lables\n",
    "Y = Y * 2 - np.ones(len(Y)) # shift label from {0, 1} to {-1, 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66b9ee13-87a9-4709-a86b-d66266c2f0dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_list = [X[i, 0, :, :] for i in range(10)]\n",
    "X = X_list\n",
    "Y_list = [Y[i] for i in range(10)]\n",
    "Y = Y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "410a2ccf-2210-4b1f-868d-e6511a632ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36078431, 0.42352941, 0.45882353, 0.43529412, 0.39607843,\n",
       "        0.35294118, 0.2745098 , 0.19215686, 0.10980392, 0.23529412,\n",
       "        0.3254902 , 0.46666667, 0.61176471, 0.72941176, 0.82745098,\n",
       "        0.8       , 0.75294118, 0.79607843, 0.8       , 0.65098039,\n",
       "        0.45098039, 0.35294118, 0.20784314, 0.        , 0.        ,\n",
       "        0.01960784, 0.03137255, 0.02352941],\n",
       "       [0.50588235, 0.54117647, 0.55294118, 0.51764706, 0.47058824,\n",
       "        0.43529412, 0.39215686, 0.34901961, 0.38039216, 0.43137255,\n",
       "        0.41176471, 0.45882353, 0.56470588, 0.67843137, 0.76470588,\n",
       "        0.70980392, 0.76078431, 0.75686275, 0.69803922, 0.55686275,\n",
       "        0.43137255, 0.36078431, 0.22352941, 0.04313725, 0.02352941,\n",
       "        0.01568627, 0.00784314, 0.01176471],\n",
       "       [0.55294118, 0.57254902, 0.58039216, 0.56078431, 0.5254902 ,\n",
       "        0.50196078, 0.49411765, 0.49411765, 0.54901961, 0.61176471,\n",
       "        0.56078431, 0.5372549 , 0.56470588, 0.63529412, 0.70588235,\n",
       "        0.64705882, 0.62352941, 0.65098039, 0.60784314, 0.52941176,\n",
       "        0.49411765, 0.43137255, 0.30980392, 0.21568627, 0.03137255,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.47058824, 0.49411765, 0.52941176, 0.54509804, 0.54509804,\n",
       "        0.54117647, 0.56078431, 0.58823529, 0.52941176, 0.6745098 ,\n",
       "        0.69803922, 0.66666667, 0.62745098, 0.63529412, 0.69019608,\n",
       "        0.64705882, 0.63921569, 0.68627451, 0.63137255, 0.54901961,\n",
       "        0.51764706, 0.43137255, 0.3372549 , 0.3254902 , 0.18039216,\n",
       "        0.10980392, 0.0745098 , 0.10588235],\n",
       "       [0.41176471, 0.44705882, 0.49411765, 0.52941176, 0.56078431,\n",
       "        0.60392157, 0.64705882, 0.68235294, 0.57647059, 0.70196078,\n",
       "        0.7254902 , 0.71372549, 0.6745098 , 0.6627451 , 0.69803922,\n",
       "        0.65098039, 0.69411765, 0.70588235, 0.61960784, 0.55294118,\n",
       "        0.56470588, 0.52941176, 0.4745098 , 0.49019608, 0.43137255,\n",
       "        0.34901961, 0.30196078, 0.31764706],\n",
       "       [0.39607843, 0.44313725, 0.49019608, 0.52156863, 0.58039216,\n",
       "        0.65882353, 0.70980392, 0.71764706, 0.70588235, 0.70588235,\n",
       "        0.63921569, 0.65098039, 0.67843137, 0.68627451, 0.70196078,\n",
       "        0.64313725, 0.6745098 , 0.6627451 , 0.61960784, 0.62352941,\n",
       "        0.69803922, 0.71764706, 0.65882353, 0.60392157, 0.5372549 ,\n",
       "        0.48235294, 0.44313725, 0.44705882],\n",
       "       [0.3254902 , 0.41960784, 0.49411765, 0.53333333, 0.60784314,\n",
       "        0.69803922, 0.70980392, 0.65490196, 0.65490196, 0.59607843,\n",
       "        0.51372549, 0.58823529, 0.67843137, 0.69411765, 0.70980392,\n",
       "        0.65882353, 0.7254902 , 0.70980392, 0.69411765, 0.67058824,\n",
       "        0.66666667, 0.69411765, 0.6627451 , 0.57254902, 0.55686275,\n",
       "        0.53333333, 0.50980392, 0.49803922],\n",
       "       [0.24313725, 0.38039216, 0.49803922, 0.56470588, 0.65098039,\n",
       "        0.73333333, 0.68627451, 0.57647059, 0.47058824, 0.44705882,\n",
       "        0.43921569, 0.58431373, 0.69411765, 0.69411765, 0.72156863,\n",
       "        0.70196078, 0.71764706, 0.69803922, 0.6745098 , 0.57254902,\n",
       "        0.47843137, 0.56078431, 0.6745098 , 0.66666667, 0.63137255,\n",
       "        0.62745098, 0.59607843, 0.55294118],\n",
       "       [0.17647059, 0.35294118, 0.53333333, 0.58823529, 0.74901961,\n",
       "        0.69411765, 0.61960784, 0.54509804, 0.51372549, 0.4627451 ,\n",
       "        0.46666667, 0.56078431, 0.66666667, 0.72156863, 0.75294118,\n",
       "        0.78823529, 0.79215686, 0.72156863, 0.64313725, 0.57254902,\n",
       "        0.50980392, 0.50196078, 0.59607843, 0.71372549, 0.72941176,\n",
       "        0.7254902 , 0.61960784, 0.54117647],\n",
       "       [0.14509804, 0.34901961, 0.54509804, 0.68235294, 0.70980392,\n",
       "        0.63921569, 0.51764706, 0.48235294, 0.4627451 , 0.48235294,\n",
       "        0.54509804, 0.63529412, 0.70588235, 0.7372549 , 0.75686275,\n",
       "        0.77254902, 0.76078431, 0.70980392, 0.63921569, 0.55686275,\n",
       "        0.48235294, 0.46666667, 0.5372549 , 0.62745098, 0.69019608,\n",
       "        0.70980392, 0.62352941, 0.54509804],\n",
       "       [0.09803922, 0.34117647, 0.56470588, 0.74509804, 0.63921569,\n",
       "        0.56862745, 0.45098039, 0.46666667, 0.46666667, 0.54901961,\n",
       "        0.64313725, 0.70196078, 0.72941176, 0.75294118, 0.77254902,\n",
       "        0.77647059, 0.74901961, 0.7254902 , 0.6627451 , 0.56862745,\n",
       "        0.48235294, 0.45098039, 0.49411765, 0.54509804, 0.65098039,\n",
       "        0.70588235, 0.63921569, 0.55294118],\n",
       "       [0.08235294, 0.36862745, 0.63137255, 0.7254902 , 0.58823529,\n",
       "        0.5254902 , 0.48627451, 0.50588235, 0.52156863, 0.61960784,\n",
       "        0.69803922, 0.70980392, 0.71764706, 0.76470588, 0.79607843,\n",
       "        0.79215686, 0.74901961, 0.74117647, 0.69019608, 0.58823529,\n",
       "        0.49019608, 0.45098039, 0.46666667, 0.49803922, 0.61960784,\n",
       "        0.71372549, 0.66666667, 0.55686275],\n",
       "       [0.09019608, 0.43529412, 0.72156863, 0.65490196, 0.56470588,\n",
       "        0.48627451, 0.50588235, 0.47843137, 0.54509804, 0.62745098,\n",
       "        0.68627451, 0.69019608, 0.71764706, 0.78431373, 0.80784314,\n",
       "        0.78823529, 0.74509804, 0.73333333, 0.69019608, 0.60392157,\n",
       "        0.50196078, 0.44313725, 0.44705882, 0.4745098 , 0.56862745,\n",
       "        0.70588235, 0.67843137, 0.55294118],\n",
       "       [0.10588235, 0.49019608, 0.72941176, 0.56078431, 0.52156863,\n",
       "        0.42745098, 0.42352941, 0.38431373, 0.5254902 , 0.59215686,\n",
       "        0.65490196, 0.69019608, 0.74901961, 0.80784314, 0.81176471,\n",
       "        0.77647059, 0.75686275, 0.7372549 , 0.70980392, 0.65490196,\n",
       "        0.55294118, 0.45882353, 0.44705882, 0.48627451, 0.50980392,\n",
       "        0.68627451, 0.67843137, 0.53333333],\n",
       "       [0.16470588, 0.54901961, 0.65882353, 0.50588235, 0.48627451,\n",
       "        0.42745098, 0.36470588, 0.4       , 0.55686275, 0.6       ,\n",
       "        0.65490196, 0.70588235, 0.77254902, 0.81960784, 0.81960784,\n",
       "        0.79215686, 0.76470588, 0.73333333, 0.7254902 , 0.70980392,\n",
       "        0.60392157, 0.47058824, 0.43921569, 0.48627451, 0.4745098 ,\n",
       "        0.67843137, 0.68235294, 0.51764706],\n",
       "       [0.25098039, 0.61176471, 0.60784314, 0.50980392, 0.48627451,\n",
       "        0.49019608, 0.39215686, 0.5254902 , 0.62745098, 0.64313725,\n",
       "        0.6745098 , 0.72156863, 0.77254902, 0.81568627, 0.82745098,\n",
       "        0.82352941, 0.74901961, 0.70980392, 0.71764706, 0.7254902 ,\n",
       "        0.61960784, 0.45490196, 0.40392157, 0.45882353, 0.4745098 ,\n",
       "        0.68627451, 0.69019608, 0.50980392],\n",
       "       [0.35686275, 0.65098039, 0.50196078, 0.46666667, 0.4       ,\n",
       "        0.36862745, 0.42352941, 0.50196078, 0.62352941, 0.71372549,\n",
       "        0.70196078, 0.72941176, 0.79215686, 0.80784314, 0.82352941,\n",
       "        0.78039216, 0.78823529, 0.75294118, 0.74509804, 0.7254902 ,\n",
       "        0.64705882, 0.57254902, 0.49019608, 0.4       , 0.50196078,\n",
       "        0.54901961, 0.71372549, 0.47843137],\n",
       "       [0.40392157, 0.63137255, 0.47843137, 0.4627451 , 0.43137255,\n",
       "        0.39607843, 0.43137255, 0.49411765, 0.59607843, 0.69803922,\n",
       "        0.69803922, 0.74117647, 0.80784314, 0.82352941, 0.84705882,\n",
       "        0.81568627, 0.78039216, 0.73333333, 0.7254902 , 0.7254902 ,\n",
       "        0.68235294, 0.62352941, 0.54117647, 0.43921569, 0.46666667,\n",
       "        0.52941176, 0.69803922, 0.45882353],\n",
       "       [0.49803922, 0.60784314, 0.42745098, 0.40784314, 0.41960784,\n",
       "        0.38823529, 0.40784314, 0.45882353, 0.58039216, 0.69019608,\n",
       "        0.70196078, 0.74901961, 0.80784314, 0.81176471, 0.82745098,\n",
       "        0.80392157, 0.78039216, 0.72156863, 0.70980392, 0.71764706,\n",
       "        0.70196078, 0.66666667, 0.58431373, 0.48235294, 0.43529412,\n",
       "        0.51372549, 0.68627451, 0.43529412],\n",
       "       [0.55686275, 0.55294118, 0.36078431, 0.32941176, 0.37647059,\n",
       "        0.35294118, 0.36862745, 0.40784314, 0.52156863, 0.63921569,\n",
       "        0.6745098 , 0.74509804, 0.80784314, 0.80392157, 0.81568627,\n",
       "        0.79215686, 0.78039216, 0.72156863, 0.70588235, 0.70980392,\n",
       "        0.69019608, 0.66666667, 0.60784314, 0.52156863, 0.41960784,\n",
       "        0.50196078, 0.67843137, 0.42745098],\n",
       "       [0.52941176, 0.48627451, 0.36862745, 0.35686275, 0.43529412,\n",
       "        0.41568627, 0.42352941, 0.44313725, 0.46666667, 0.58431373,\n",
       "        0.63529412, 0.7372549 , 0.82352941, 0.82745098, 0.84705882,\n",
       "        0.83137255, 0.77254902, 0.72156863, 0.70980392, 0.70196078,\n",
       "        0.67058824, 0.65490196, 0.62745098, 0.57254902, 0.41176471,\n",
       "        0.4745098 , 0.64705882, 0.41568627],\n",
       "       [0.50980392, 0.50196078, 0.51372549, 0.52941176, 0.62745098,\n",
       "        0.60784314, 0.61176471, 0.60392157, 0.55294118, 0.63529412,\n",
       "        0.65490196, 0.74901961, 0.83137255, 0.83137255, 0.84705882,\n",
       "        0.83137255, 0.74901961, 0.70980392, 0.70196078, 0.69803922,\n",
       "        0.66666667, 0.65490196, 0.63529412, 0.58823529, 0.40392157,\n",
       "        0.42352941, 0.59607843, 0.40392157],\n",
       "       [0.54901961, 0.58039216, 0.68235294, 0.67843137, 0.76470588,\n",
       "        0.74901961, 0.76470588, 0.75294118, 0.71372549, 0.74901961,\n",
       "        0.70588235, 0.75686275, 0.81960784, 0.80784314, 0.81568627,\n",
       "        0.8       , 0.72941176, 0.68627451, 0.67843137, 0.68627451,\n",
       "        0.6627451 , 0.64313725, 0.6       , 0.52941176, 0.4       ,\n",
       "        0.38039216, 0.54901961, 0.40784314],\n",
       "       [0.59215686, 0.63137255, 0.75686275, 0.71372549, 0.76862745,\n",
       "        0.76078431, 0.79607843, 0.79607843, 0.79607843, 0.8       ,\n",
       "        0.72156863, 0.74901961, 0.80784314, 0.8       , 0.81568627,\n",
       "        0.80784314, 0.72156863, 0.66666667, 0.65490196, 0.67058824,\n",
       "        0.65490196, 0.62352941, 0.54901961, 0.45098039, 0.40392157,\n",
       "        0.35686275, 0.5254902 , 0.41568627],\n",
       "       [0.63529412, 0.69019608, 0.74509804, 0.77254902, 0.78823529,\n",
       "        0.80392157, 0.80784314, 0.8       , 0.8       , 0.79607843,\n",
       "        0.79607843, 0.81176471, 0.82745098, 0.82745098, 0.81568627,\n",
       "        0.79607843, 0.67058824, 0.69019608, 0.71764706, 0.7372549 ,\n",
       "        0.73333333, 0.70980392, 0.6745098 , 0.64705882, 0.44313725,\n",
       "        0.33333333, 0.38039216, 0.49803922],\n",
       "       [0.65882353, 0.70588235, 0.75294118, 0.77647059, 0.79215686,\n",
       "        0.81176471, 0.82352941, 0.82352941, 0.82745098, 0.82352941,\n",
       "        0.82745098, 0.83921569, 0.85490196, 0.85882353, 0.84313725,\n",
       "        0.82745098, 0.76078431, 0.76470588, 0.76862745, 0.76470588,\n",
       "        0.75294118, 0.7254902 , 0.69019608, 0.66666667, 0.58039216,\n",
       "        0.46666667, 0.45098039, 0.49411765],\n",
       "       [0.67843137, 0.72156863, 0.76470588, 0.78431373, 0.8       ,\n",
       "        0.82745098, 0.84313725, 0.84705882, 0.85098039, 0.84705882,\n",
       "        0.85098039, 0.8627451 , 0.87843137, 0.88235294, 0.86666667,\n",
       "        0.85098039, 0.83137255, 0.81960784, 0.80392157, 0.78823529,\n",
       "        0.76862745, 0.74117647, 0.71372549, 0.69411765, 0.69019608,\n",
       "        0.6       , 0.54509804, 0.51764706],\n",
       "       [0.67843137, 0.7254902 , 0.77647059, 0.8       , 0.81960784,\n",
       "        0.83921569, 0.85098039, 0.85098039, 0.85490196, 0.85098039,\n",
       "        0.85098039, 0.8627451 , 0.87843137, 0.88235294, 0.86666667,\n",
       "        0.85098039, 0.83529412, 0.81960784, 0.8       , 0.78823529,\n",
       "        0.77647059, 0.75686275, 0.72941176, 0.70588235, 0.69411765,\n",
       "        0.65882353, 0.60392157, 0.54509804]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e1e506f-4f4e-480f-bc0d-263157f82af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00+0.j, 1.19889621e-17+0.j],\n",
       "       [1.19889621e-17+0.j, 1.00000000e+00+0.j]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#qml.matrix(qml.RY(0.2*np.pi,0)@qml.RY(-0.2*np.pi,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3642c9c5-5e9a-4413-ba5d-43a92d14f29e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d15637b6-daf2-4218-8601-50bb49d36d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_x=['x0','x1','x2','x3','x4']\n",
    "index_y=['y0','y1','y2','y3','y4']\n",
    "def encoder(image):\n",
    "    for wire in (index_x+index_y):\n",
    "        qml.Hadamard(wires=wire)\n",
    "    for i in range(len(image)):\n",
    "        y = bin(i)[2:]\n",
    "        y = '0'*(5-len(y)) + y\n",
    "        for j in range(len(image[0])):\n",
    "            if image[i][j]>0.001:\n",
    "                x = bin(j)[2:]\n",
    "                x = '0'*(5-len(x)) + x\n",
    "                qml.RY(image[i][j]/2*np.pi,wires='gray')\n",
    "                qml.MultiControlledX(control_wires=(index_x+index_y), wires='gray', control_values=x+y)\n",
    "                qml.RY(image[i][j]/2*np.pi,wires='gray')\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcfb9819-cede-45f0-bf6e-4c4d8adebe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entangling_layer0(input_wires,output_wires,weights):\n",
    "    \n",
    "    weights_ = (weight for weight in weights)\n",
    "    for i in input_wires:\n",
    "        for j in output_wires:\n",
    "            qml.CNOT(wires=[i,j])\n",
    "            \n",
    "            param = next(weights_)\n",
    "            qml.RZ(param, wires=j)\n",
    "            \n",
    "            param = next(weights_)\n",
    "            qml.RX(param, wires=j) \n",
    "            \n",
    "            qml.CNOT(wires=[i,j])\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29ffaa96-bd86-4956-9b1a-cc38486845a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entangling_layer1(wires,weights):\n",
    "    n=len(wires)\n",
    "    weights_ = (weight for weight in weights)\n",
    "    for i in range(1,n):\n",
    "        j = 0\n",
    "        r = []\n",
    "        while j <= n-1:\n",
    "            if j not in r:\n",
    "                qml.CNOT([wires[j],wires[j+i]])\n",
    "                r += [j+1]\n",
    "            \n",
    "                param = next(weights_)\n",
    "                qml.RZ(param, wires=j)\n",
    "            \n",
    "                param = next(weights_)\n",
    "                qml.RX(param, wires=j) \n",
    "            \n",
    "                qml.CNOT([wires[j],wires[j+i]])\n",
    "                j += 1\n",
    "        for j in r:\n",
    "            qml.CNOT([wires[j],wires[j+i]])\n",
    "            \n",
    "            param = next(weights_)\n",
    "            qml.RZ(param, wires=j)\n",
    "            \n",
    "            param = next(weights_)\n",
    "            qml.RX(param, wires=j) \n",
    "            \n",
    "            qml.CNOT([wires[j],wires[j+i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e15f8031-836a-43fd-8047-a22000a88b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwires = [0,1,2,3]\\nnp.random.seed(0)\\nweights= 0.01 * np.random.randn(12, requires_grad=True)\\n\\ndev = qml.device(\"default.qubit\", wires=wires)\\n@qml.qnode(dev)\\n\\ndef entangling_layer1(wires,weights):\\n    n=len(wires)\\n    weights_ = (weight for weight in weights)\\n    for i in range(1,n):\\n        j = 0\\n        r = []\\n        while j <= n-i-1:\\n            if j not in r:\\n                qml.CNOT([wires[j],wires[j+i]])\\n                r += [j+1]\\n            \\n                param = next(weights_)\\n                qml.RZ(param, wires=j)\\n            \\n                param = next(weights_)\\n                qml.RX(param, wires=j) \\n            \\n                qml.CNOT([wires[j],wires[j+i]])\\n            j += 1\\n        for j in r:\\n            if j+i <= n-1:\\n                qml.CNOT([wires[j],wires[j+i]])\\n            \\n                param = next(weights_)\\n                qml.RZ(param, wires=j)\\n            \\n                param = next(weights_)\\n                qml.RX(param, wires=j) \\n            \\n                qml.CNOT([wires[j],wires[j+i]])\\n    return qml.probs(wires[0])\\n            \\nprint(qml.draw(entangling_layer1)(wires,weights))'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "wires = [0,1,2,3]\n",
    "np.random.seed(0)\n",
    "weights= 0.01 * np.random.randn(12, requires_grad=True)\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=wires)\n",
    "@qml.qnode(dev)\n",
    "\n",
    "def entangling_layer1(wires,weights):\n",
    "    n=len(wires)\n",
    "    weights_ = (weight for weight in weights)\n",
    "    for i in range(1,n):\n",
    "        j = 0\n",
    "        r = []\n",
    "        while j <= n-i-1:\n",
    "            if j not in r:\n",
    "                qml.CNOT([wires[j],wires[j+i]])\n",
    "                r += [j+1]\n",
    "            \n",
    "                param = next(weights_)\n",
    "                qml.RZ(param, wires=j)\n",
    "            \n",
    "                param = next(weights_)\n",
    "                qml.RX(param, wires=j) \n",
    "            \n",
    "                qml.CNOT([wires[j],wires[j+i]])\n",
    "            j += 1\n",
    "        for j in r:\n",
    "            if j+i <= n-1:\n",
    "                qml.CNOT([wires[j],wires[j+i]])\n",
    "            \n",
    "                param = next(weights_)\n",
    "                qml.RZ(param, wires=j)\n",
    "            \n",
    "                param = next(weights_)\n",
    "                qml.RX(param, wires=j) \n",
    "            \n",
    "                qml.CNOT([wires[j],wires[j+i]])\n",
    "    return qml.probs(wires[0])\n",
    "            \n",
    "print(qml.draw(entangling_layer1)(wires,weights))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddde1fe7-38ef-4d03-bfcb-13628680c92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training circuit\n",
    "encoder_wires = ['x0','x1','x2','x3','x4','y0','y1','y2','y3','y4','gray','train']\n",
    "dev = qml.device(\"default.qubit\", wires=encoder_wires)\n",
    "@qml.qnode(dev)\n",
    "def circuit(weights, image):\n",
    "    encoder(image)\n",
    "    entangling_layer0(['x0','x1','x2','x3','x4','y0','y1','y2','y3','y4','gray'],['train'],weights)\n",
    "    #entangling_layer1(['x0','x1','x2','x3','x4','y0','y1','y2','y3','y4','gray'],weights)\n",
    "    return qml.expval(qml.PauliZ('train'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71d089e8-66a0-4336-8c91-3349a6312a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_classifier(weights, bias, x):\n",
    "    return circuit(weights, x) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7149a5f-924b-4ed9-b428-56d7b63e3b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_loss(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "\n",
    "    loss = loss / len(labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68923dd4-a70b-4515-a0b6-850efb82a448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(labels, predictions):\n",
    "\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        if abs(l - p) < 1e-5:\n",
    "            loss = loss + 1\n",
    "    loss = loss / len(labels)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e02a7d7e-0375-45b5-aa95-5941e52ff0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(weights, bias, X, Y):\n",
    "    predictions = [variational_classifier(weights, bias, x) for x in X]\n",
    "    return square_loss(Y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6cd6f87-99a8-416f-ba69-5004133ec3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "weights_init = 0.01 * np.random.randn(22, requires_grad=True)\n",
    "#weights_init = 0.01 * np.random.randn(110, requires_grad=True)\n",
    "bias_init = np.array(0.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b06e6df-a5ea-4349-a87f-5a213272bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pennylane.optimize import NesterovMomentumOptimizer\n",
    "opt = NesterovMomentumOptimizer(0.5)\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b588f62-2cca-43e6-8b6f-11a0370bac0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m it \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Update the weights by one optimizer step\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     batch_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(X), (batch_size,))\n\u001b[0;32m----> 8\u001b[0m     X_batch \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      9\u001b[0m     Y_batch \u001b[38;5;241m=\u001b[39m Y[batch_index]\n\u001b[1;32m     10\u001b[0m     weights, bias, _, _ \u001b[38;5;241m=\u001b[39m opt\u001b[38;5;241m.\u001b[39mstep(cost, weights, bias, X_batch, Y_batch)\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "# Training the circuit\n",
    "weights = weights_init\n",
    "bias = bias_init\n",
    "for it in range(2):\n",
    "\n",
    "    # Update the weights by one optimizer step\n",
    "    batch_index = np.random.randint(0, len(X), (batch_size,))\n",
    "    X_batch = X[batch_index]\n",
    "    Y_batch = Y[batch_index]\n",
    "    weights, bias, _, _ = opt.step(cost, weights, bias, X_batch, Y_batch)\n",
    "\n",
    "    # Compute accuracy\n",
    "    predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X]\n",
    "    acc = accuracy(Y, predictions)\n",
    "\n",
    "    print(\n",
    "        \"Iter: {:5d} | Cost: {:0.7f} | Accuracy: {:0.7f} \".format(\n",
    "            it + 1, cost(weights, bias, X, Y), acc\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c931be-7dc5-486c-98b8-e873532e595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model with test dataset\n",
    "\n",
    "test_X=(np.load('images.npy')*255)[495:505] # train images\n",
    "\n",
    "test_label=np.load('labels.npy')[495:505]\n",
    "test_Y = np.array([int(y) for y in test_label]) # train lables\n",
    "test_Y = test_Y * 2 - np.ones(len(test_Y)) # shift label from {0, 1} to {-1, 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508b0e4c-e487-4a54-90d6-62e8c8d8928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = [np.sign(variational_classifier(weights, bias, x)) for x in test_X]\n",
    "test_acc = accuracy(test_Y, test_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
